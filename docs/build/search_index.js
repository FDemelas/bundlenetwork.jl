var documenterSearchIndex = {"docs":
[{"location":"api/training.html#Training-API-Reference","page":"Training Functions","title":"Training API Reference","text":"","category":"section"},{"location":"api/training.html#Batch-Training","page":"Training Functions","title":"Batch Training","text":"","category":"section"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"main(args)","category":"page"},{"location":"api/training.html#Function:-main","page":"Training Functions","title":"Function: main","text":"","category":"section"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Main entry point for batch training.","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Source: runs/train_batch.jl","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Arguments:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"args::Vector{String}: Command-line arguments","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Required Arguments:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"--lr::Float64: Learning rate\n--mti::Int64: Maximum training instances\n--mvi::Int64: Maximum validation instances  \n--seed::Int64: Random seed\n--maxItBack::Int64: Max iterations for backward pass\n--maxEP::Int64: Maximum epochs","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Optional Arguments:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"--data::String: Instance folder path (default: \"./data/MCNDforTest/\")\n--decay::Float64: Learning rate decay (default: 0.9)\n--lambda::Float32: Final point weight (default: 0.0)\n--gamma::Float32: Telescopic weight (default: 0.0)\n--cn::Int64: Gradient clipping norm (default: 5)\n--batch_size::Int64: Batch size (default: 1)\n--h_representation::Int64: Hidden size (default: 64)","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Output Files:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"nn.bson: Final model\nnn_best.bson: Best validation model\nloss.json, obj.json, gaps.json: Training metrics\nobj_val.json, gaps_val.json: Validation metrics","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Example:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"args = [\n    \"--data\", \"./data/MCNDforTest/\",\n    \"--lr\", \"0.001\",\n    \"--mti\", \"100\",\n    \"--mvi\", \"20\",\n    \"--seed\", \"42\",\n    \"--maxItBack\", \"50\",\n    \"--maxEP\", \"100\"\n]\nmain(args)","category":"page"},{"location":"api/training.html#Episodic-Training","page":"Training Functions","title":"Episodic Training","text":"","category":"section"},{"location":"api/training.html#Function:-ep_train_and_val","page":"Training Functions","title":"Function: ep_train_and_val","text":"","category":"section"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Execute episodic training and validation.","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Source: runs/train_episodic.jl","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Signature:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"function ep_train_and_val(\n    folder, directory, dataset, gold, \n    idxs_train, idxs_val, opt;\n    maxEP=10, maxIT=50, kwargs...\n)","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Arguments:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"folder::String: Instance folder path\ndirectory::Vector{String}: File list\ndataset::Vector{Tuple}: (filename, objective) pairs\ngold::Dict: Optimal solutions\nidxs_train::Vector{Int}: Training indices\nidxs_val::Vector{Int}: Validation indices\nopt: Flux optimizer","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Keyword Arguments:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"maxEP::Int=10: Maximum epochs\nmaxIT::Int=50: Bundle iterations\ncr_init::Bool=false: Use CR initialization\nexactGrad::Bool=true: Exact gradient formula\ntelescopic::Bool=false: Telescopic loss\nγ::Float64=0.1: Telescopic weight decay\ninstance_features::Bool=false: Include instance features","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Returns: Nothing (saves to disk)","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Example:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"opt = Flux.OptimiserChain(Flux.Optimise.Adam(0.001), ClipNorm(5))\nep_train_and_val(\n    \"./data/\", directory, dataset, gold, \n    1:100, 101:120, opt;\n    maxEP=50, maxIT=50, telescopic=true\n)","category":"page"},{"location":"api/training.html#Function:-saveJSON","page":"Training Functions","title":"Function: saveJSON","text":"","category":"section"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Helper to save dictionary to JSON.","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Signature:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"function saveJSON(name::String, res::Dict)","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Arguments:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"name::String: Output file path\nres::Dict: Dictionary to save","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Example:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"results = Dict(\"loss\" => [1.0, 0.8, 0.6])\nsaveJSON(\"results.json\", results)","category":"page"},{"location":"api/training.html#Common-Helper-Functions","page":"Training Functions","title":"Common Helper Functions","text":"","category":"section"},{"location":"api/training.html#gap","page":"Training Functions","title":"gap","text":"","category":"section"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Calculate relative percentage gap.","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Signature:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"gap(a, b) = abs(a - b) / max(a, b) * 100","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Arguments:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"a::Float64: First value (solution)\nb::Float64: Second value (optimal)","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Returns: Float64 - Percentage gap","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"Example:","category":"page"},{"location":"api/training.html","page":"Training Functions","title":"Training Functions","text":"solution = 95.0\noptimal = 100.0\ng = gap(solution, optimal)  # Returns 5.0","category":"page"},{"location":"tutorials/episodic_training.html#Episodic-Training-Tutorial","page":"Episodic Training","title":"Episodic Training Tutorial","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Episodic training processes one instance at a time, updating the model after each instance.","category":"page"},{"location":"tutorials/episodic_training.html#When-to-Use-Episodic-Training","page":"Episodic Training","title":"When to Use Episodic Training","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Use episodic training when:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Instances vary greatly in size\nMemory is limited\nYou want online learning behavior\nTesting instance-specific adaptation","category":"page"},{"location":"tutorials/episodic_training.html#Basic-Episodic-Training","page":"Episodic Training","title":"Basic Episodic Training","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"julia runs/train_episodic.jl \\\n  --data ./data/MCNDforTest/ \\\n  --lr 0.001 \\\n  --mti 100 \\\n  --mvi 20 \\\n  --seed 42 \\\n  --maxIT 50 \\\n  --maxEP 100","category":"page"},{"location":"tutorials/episodic_training.html#Key-Differences-from-Batch-Training","page":"Episodic Training","title":"Key Differences from Batch Training","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Feature Batch Training Episodic Training\nUpdate frequency Per batch Per instance\nGradient stability Higher Lower\nMemory usage Higher Lower\nTraining speed Slower per epoch Faster per epoch\nValidation maxItVal iterations 5×maxIT iterations","category":"page"},{"location":"tutorials/episodic_training.html#Configuration-Options","page":"Episodic Training","title":"Configuration Options","text":"","category":"section"},{"location":"tutorials/episodic_training.html#Initialization-Strategy","page":"Episodic Training","title":"Initialization Strategy","text":"","category":"section"},{"location":"tutorials/episodic_training.html#Zero-Initialization-(Default)","page":"Episodic Training","title":"Zero Initialization (Default)","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"--cr_init false","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Start dual variables at zero.","category":"page"},{"location":"tutorials/episodic_training.html#Cutting-Plane-Relaxation","page":"Episodic Training","title":"Cutting-Plane Relaxation","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"--cr_init true","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Warm-start from CR solution (slower initialization, may improve convergence).","category":"page"},{"location":"tutorials/episodic_training.html#Loss-Functions","page":"Episodic Training","title":"Loss Functions","text":"","category":"section"},{"location":"tutorials/episodic_training.html#Standard-Loss-(Default)","page":"Episodic Training","title":"Standard Loss (Default)","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"--telescopic false","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Loss based on final point only.","category":"page"},{"location":"tutorials/episodic_training.html#Telescopic-Loss","page":"Episodic Training","title":"Telescopic Loss","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"--telescopic true \\\n--gamma 0.1","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Loss includes all visited points: L = -Σ γ^i * ϕ(x_i)","category":"page"},{"location":"tutorials/episodic_training.html#Feature-Engineering","page":"Episodic Training","title":"Feature Engineering","text":"","category":"section"},{"location":"tutorials/episodic_training.html#Instance-Features","page":"Episodic Training","title":"Instance Features","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"--instance_features true  # Include linear relaxation features\n--instance_features false # Use only bundle state","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Instance features include:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Linear relaxation dual variables\nConstraint structure information\nProblem-specific characteristics","category":"page"},{"location":"tutorials/episodic_training.html#Proximity-Parameter-Strategy","page":"Episodic Training","title":"Proximity Parameter Strategy","text":"","category":"section"},{"location":"tutorials/episodic_training.html#Learned-Parameter-(Default)","page":"Episodic Training","title":"Learned Parameter (Default)","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"--single_prediction false","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Neural network predicts t at each iteration.","category":"page"},{"location":"tutorials/episodic_training.html#Constant-Parameter","page":"Episodic Training","title":"Constant Parameter","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"--single_prediction true","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Use fixed proximity parameter throughout.","category":"page"},{"location":"tutorials/episodic_training.html#Complete-Example","page":"Episodic Training","title":"Complete Example","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"julia runs/train_episodic.jl \\\n  --data ./data/MCNDforTest/ \\\n  --lr 0.001 \\\n  --cn 5 \\\n  --mti 200 \\\n  --mvi 40 \\\n  --seed 42 \\\n  --maxIT 50 \\\n  --maxEP 100 \\\n  --cr_init false \\\n  --exactGrad true \\\n  --telescopic true \\\n  --gamma 0.1 \\\n  --instance_features true \\\n  --single_prediction false \\\n  --sample_inside true","category":"page"},{"location":"tutorials/episodic_training.html#Validation-Behavior","page":"Episodic Training","title":"Validation Behavior","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Episodic training validates at three iteration counts:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"maxIT: Same as training\n2×maxIT: Medium-length run\n5×maxIT: Extended run","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"This helps assess:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Short-term performance\nConvergence stability\nLong-term behavior","category":"page"},{"location":"tutorials/episodic_training.html#Monitoring","page":"Episodic Training","title":"Monitoring","text":"","category":"section"},{"location":"tutorials/episodic_training.html#TensorBoard-Metrics","page":"Episodic Training","title":"TensorBoard Metrics","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"tensorboard --logdir resLogs/","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Unique to episodic training:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Validation/GAP_percentage_li: Gap at maxIT\nValidation x2/GAP_percentage: Gap at 2×maxIT\nValidation x5/GAP_percentage: Gap at 5×maxIT","category":"page"},{"location":"tutorials/episodic_training.html#Comparing-Validation-Lengths","page":"Episodic Training","title":"Comparing Validation Lengths","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Good convergence pattern:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"maxIT gap:   5.2%\n2×maxIT gap: 3.1%\n5×maxIT gap: 2.0%","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Poor convergence:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"maxIT gap:   5.2%\n2×maxIT gap: 5.0%\n5×maxIT gap: 4.9%","category":"page"},{"location":"tutorials/episodic_training.html#Output-Files","page":"Episodic Training","title":"Output Files","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Similar to batch training, plus:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Validation metrics at multiple iteration counts","category":"page"},{"location":"tutorials/episodic_training.html#Batch-vs.-Episodic:-When-to-Choose","page":"Episodic Training","title":"Batch vs. Episodic: When to Choose","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Choose Batch Training if:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"✓ Instances are similar in size\n✓ You have sufficient memory\n✓ You want stable gradients\n✓ Training time is not critical","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Choose Episodic Training if:","category":"page"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"✓ Instances vary greatly\n✓ Memory is limited\n✓ You want faster epoch times\n✓ Testing online learning","category":"page"},{"location":"tutorials/episodic_training.html#Next-Steps","page":"Episodic Training","title":"Next Steps","text":"","category":"section"},{"location":"tutorials/episodic_training.html","page":"Episodic Training","title":"Episodic Training","text":"Compare with Batch Training\nLearn Testing & Evaluation\nSee Hyperparameter Tuning","category":"page"},{"location":"manual/architecture.html#Neural-Network-Architecture","page":"Architecture","title":"Neural Network Architecture","text":"","category":"section"},{"location":"manual/architecture.html#Overview","page":"Architecture","title":"Overview","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"The neural network architecture is designed to predict bundle method parameters  from the current optimization state.","category":"page"},{"location":"manual/architecture.html#Model-Components","page":"Architecture","title":"Model Components","text":"","category":"section"},{"location":"manual/architecture.html#Encoder","page":"Architecture","title":"Encoder","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Processes instance features and bundle state:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Input Features → Linear → Activation → Linear → Hidden Representation","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Input features include:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Bundle gradients (subgradients)\nFunction values\nDual variables (optional: from CR)\nInstance structure (optional: graph features)","category":"page"},{"location":"manual/architecture.html#Decoder-for-Proximity-Parameter-(t)","page":"Architecture","title":"Decoder for Proximity Parameter (t)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Predicts the proximity parameter:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Hidden Representation → Linear → Softplus → t","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Output: Scalar proximity parameter controlling trust region size.","category":"page"},{"location":"manual/architecture.html#Decoder-for-Gradient-Aggregation-(γ)","page":"Architecture","title":"Decoder for Gradient Aggregation (γ)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Predicts weights for convex combination of gradients:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Hidden Representation → Attention → Distribution → θ","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Components:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Query Network: Generates query from hidden state\nKey Network: Generates keys from bundle components\nAttention Mechanism: Computes attention scores\nDistribution: Softmax or Sparsemax normalization","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Output: Probability distribution over bundle components.","category":"page"},{"location":"manual/architecture.html#Attention-Mechanism","page":"Architecture","title":"Attention Mechanism","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"The attention mechanism computes how to aggregate bundle gradients:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Q = QueryNetwork(hidden_state)\nK = KeyNetwork(bundle_gradients)\nV = bundle_gradients\n\nscores = Q · K^T\nθ = softmax(scores)\naggregated_gradient = Σ θ_i * V_i","category":"page"},{"location":"manual/architecture.html#Architecture-Variants","page":"Architecture","title":"Architecture Variants","text":"","category":"section"},{"location":"manual/architecture.html#Standard-Architecture-(h3false)","page":"Architecture","title":"Standard Architecture (h3=false)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Three separate hidden representations:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"One for proximity parameter\nOne for attention queries\nOne for attention keys","category":"page"},{"location":"manual/architecture.html#Compact-Architecture-(h3true)","page":"Architecture","title":"Compact Architecture (h3=true)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Single shared hidden representation for all outputs.","category":"page"},{"location":"manual/architecture.html#Model-Factory","page":"Architecture","title":"Model Factory","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Models are created via factories:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"factory = BundleNetworks.AttentionModelFactory()\nnn = BundleNetworks.create_NN(\n    factory;\n    h_representation=64,\n    h_act=softplus,\n    sampling_θ=false,\n    sampling_t=true\n)","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Parameters:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"h_representation: Hidden layer size\nh_act: Activation function\nsampling_θ: Sample attention weights\nsampling_t: Sample proximity parameter","category":"page"},{"location":"manual/architecture.html#Sampling-Strategies","page":"Architecture","title":"Sampling Strategies","text":"","category":"section"},{"location":"manual/architecture.html#Deterministic-(Default-for-Testing)","page":"Architecture","title":"Deterministic (Default for Testing)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"nn.sample_t = false\nnn.sample_γ = false","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Outputs are mean predictions.","category":"page"},{"location":"manual/architecture.html#Stochastic-(Training)","page":"Architecture","title":"Stochastic (Training)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"nn.sample_t = true\nnn.sample_γ = true","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Samples from learned distributions for exploration.","category":"page"},{"location":"manual/architecture.html#Graph-Features","page":"Architecture","title":"Graph Features","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"When use_graph=true, bipartite graph features are extracted:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Instance → Bipartite Graph → Graph Convolution → Features","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"This captures:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Variable-constraint relationships\nNetwork structure\nSparsity patterns","category":"page"},{"location":"manual/architecture.html#Activation-Functions","page":"Architecture","title":"Activation Functions","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Supported activations:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"softplus: Smooth, always positive (good for t)\nrelu: Sparse, fast\ntanh: Bounded, smooth\ngelu: Modern, smooth","category":"page"},{"location":"manual/architecture.html#Parameter-Count","page":"Architecture","title":"Parameter Count","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Typical model sizes:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"h_representation Parameters\n32 ~10K\n64 ~40K\n128 ~160K","category":"page"},{"location":"manual/architecture.html#Next-Steps","page":"Architecture","title":"Next Steps","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"See Bundle Methods for algorithm details\nLearn about Loss Functions\nExplore Hyperparameter Tuning","category":"page"},{"location":"quickstart.html#Quick-Start-Guide","page":"Quick Start","title":"Quick Start Guide","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"This guide will help you train and test your first model in under 5 minutes.","category":"page"},{"location":"quickstart.html#Step-1:-Prepare-Your-Data","page":"Quick Start","title":"Step 1: Prepare Your Data","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Ensure you have:","category":"page"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Problem instances in ./data/MCNDforTest/\n(Optional) Gold solutions in ./golds/MCNDforTest/gold.json","category":"page"},{"location":"quickstart.html#Step-2:-Train-a-Model","page":"Quick Start","title":"Step 2: Train a Model","text":"","category":"section"},{"location":"quickstart.html#Minimal-Training-Command","page":"Quick Start","title":"Minimal Training Command","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"julia runs/train_batch.jl \\\n  --data ./data/MCNDforTest/ \\\n  --lr 0.001 \\\n  --mti 50 \\\n  --mvi 10 \\\n  --seed 42 \\\n  --maxItBack 30 \\\n  --maxEP 20","category":"page"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Parameters Explained:","category":"page"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"--lr 0.001: Learning rate\n--mti 50: Use 50 training instances\n--mvi 10: Use 10 validation instances\n--seed 42: Random seed for reproducibility\n--maxItBack 30: Unroll 30 iterations for gradient computation\n--maxEP 20: Train for 20 epochs","category":"page"},{"location":"quickstart.html#What-Happens-During-Training","page":"Quick Start","title":"What Happens During Training","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Data Loading: Instances are loaded and rescaled\nModel Initialization: Neural network is created\nTraining Loop: For each epoch:\nShuffle training data\nProcess batches\nCompute gradients via unrolling\nUpdate model parameters\nValidate on validation set\nSaving: Best model and metrics are saved","category":"page"},{"location":"quickstart.html#Expected-Output","page":"Quick Start","title":"Expected Output","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Epoch 1 Training - lsp: 1234.56  gap: 15.2%\nEpoch 1 Validation - lsp: 1250.30  gap: 12.8%\nEpoch 2 Training - lsp: 1450.23  gap: 8.5%\nEpoch 2 Validation - lsp: 1480.15  gap: 7.2%\n...","category":"page"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Results are saved to: resLogs/BatchVersion_bs_1_seed42_.../","category":"page"},{"location":"quickstart.html#Step-3:-Monitor-Training","page":"Quick Start","title":"Step 3: Monitor Training","text":"","category":"section"},{"location":"quickstart.html#Using-TensorBoard","page":"Quick Start","title":"Using TensorBoard","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"tensorboard --logdir resLogs/","category":"page"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Open browser to: http://localhost:6006","category":"page"},{"location":"quickstart.html#Key-Metrics-to-Watch","page":"Quick Start","title":"Key Metrics to Watch","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"GAP_percentage: Optimality gap (lower is better)\nLSP_value: Objective value (higher is better)\nLoss_value: Training loss","category":"page"},{"location":"quickstart.html#Step-4:-Test-Your-Model","page":"Quick Start","title":"Step 4: Test Your Model","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"julia runs/test.jl \\\n  --data ./data/MCNDforTest/ \\\n  --model ./resLogs/BatchVersion_bs_1_seed42_.../ \\\n  --dataset ./resLogs/BatchVersion_bs_1_seed42_.../","category":"page"},{"location":"quickstart.html#Test-Results","page":"Quick Start","title":"Test Results","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Results saved to: res_test2_MCNDforTest.json","category":"page"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"{\n  \"instance1.dat\": {\n    \"time\": 1.234,\n    \"objs\": [0.0, 100.5, 150.3, 180.2, ...],\n    \"gaps\": [100.0, 15.2, 5.3, 2.1, ...]\n  }\n}","category":"page"},{"location":"quickstart.html#Step-5:-Analyze-Results","page":"Quick Start","title":"Step 5: Analyze Results","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"using JSON\n\n# Load results\nresults = JSON.parsefile(\"res_test2_MCNDforTest.json\")\n\n# Compute statistics\nfor (instance, data) in results\n    final_gap = data[\"gaps\"][end]\n    println(\"$instance: Final gap = $(round(final_gap, digits=2))%\")\nend","category":"page"},{"location":"quickstart.html#Next-Steps","page":"Quick Start","title":"Next Steps","text":"","category":"section"},{"location":"quickstart.html#Improve-Performance","page":"Quick Start","title":"Improve Performance","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Increase Training Data: Use more instances (--mti 200)\nTrain Longer: More epochs (--maxEP 100)\nTune Learning Rate: Try different values (--lr 0.0001)\nIncrease Model Capacity: Larger hidden size (--h_representation 128)","category":"page"},{"location":"quickstart.html#Advanced-Features","page":"Quick Start","title":"Advanced Features","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Batch Training Tutorial: Learn batch processing\nEpisodic Training Tutorial: Instance-by-instance learning\nHyperparameter Tuning: Optimize performance","category":"page"},{"location":"quickstart.html#Troubleshooting","page":"Quick Start","title":"Troubleshooting","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"See Troubleshooting if you encounter issues.","category":"page"},{"location":"examples.html#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples.html#Complete-Workflow-Example","page":"Examples","title":"Complete Workflow Example","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"This example shows a complete training-to-testing workflow.","category":"page"},{"location":"examples.html#Step-1:-Prepare-Data","page":"Examples","title":"Step 1: Prepare Data","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"mkdir -p data/my_problem\n# Add your .dat or .json files","category":"page"},{"location":"examples.html#Step-2:-Train","page":"Examples","title":"Step 2: Train","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"julia runs/train_batch.jl \\\n  --data ./data/my_problem/ \\\n  --lr 0.001 \\\n  --mti 100 \\\n  --mvi 20 \\\n  --seed 42 \\\n  --maxItBack 50 \\\n  --maxEP 100 \\\n  --batch_size 4 \\\n  --incremental true","category":"page"},{"location":"examples.html#Step-3:-Monitor","page":"Examples","title":"Step 3: Monitor","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"tensorboard --logdir resLogs/","category":"page"},{"location":"examples.html#Step-4:-Test","page":"Examples","title":"Step 4: Test","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"julia runs/test.jl \\\n  --data ./data/my_problem/ \\\n  --model ./resLogs/BatchVersion_.../ \\\n  --dataset ./resLogs/BatchVersion_.../","category":"page"},{"location":"examples.html#Step-5:-Analyze","page":"Examples","title":"Step 5: Analyze","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"using JSON, Statistics, Plots\n\n# Load results\nresults = JSON.parsefile(\"res_test2_my_problem.json\")\n\n# Plot convergence\ngaps = [data[\"gaps\"] for (_, data) in results]\nplot(gaps, alpha=0.3, xlabel=\"Iteration\", ylabel=\"Gap (%)\", \n     yscale=:log10, legend=false, title=\"Test Set Convergence\")\n\n# Compute statistics\nfinal_gaps = [g[end] for g in gaps]\nprintln(\"Mean: $(mean(final_gaps))%\")\nprintln(\"Median: $(median(final_gaps))%\")","category":"page"},{"location":"examples.html#More-Examples","page":"Examples","title":"More Examples","text":"","category":"section"},{"location":"examples.html","page":"Examples","title":"Examples","text":"See individual tutorial pages for detailed examples:","category":"page"},{"location":"examples.html","page":"Examples","title":"Examples","text":"Batch Training Examples\nEpisodic Training Examples\nTesting Examples","category":"page"},{"location":"tutorials/testing.html#Testing-and-Evaluation-Tutorial","page":"Inference & Evaluation","title":"Testing & Evaluation Tutorial","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Learn how to evaluate trained models on test instances.","category":"page"},{"location":"tutorials/testing.html#Basic-Testing","page":"Inference & Evaluation","title":"Basic Testing","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"julia runs/test.jl \\\n  --data ./data/MCNDforTest/ \\\n  --model ./resLogs/BatchVersion_bs_1_seed42_.../ \\\n  --dataset ./resLogs/BatchVersion_bs_1_seed42_.../","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Arguments:","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"--data: Path to instance folder\n--model: Path to folder containing trained model (nnbestLV.bson or nnbest.bson)\n--dataset: Path to folder containing dataset.json","category":"page"},{"location":"tutorials/testing.html#What-the-Test-Script-Does","page":"Inference & Evaluation","title":"What the Test Script Does","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Load Model: Reads trained neural network from BSON file\nLoad Test Split: Reads test instance list from dataset.json\nLoad Instances: Processes each test instance\nRun Bundle Method: Solves with NN guidance for 100 iterations (default)\nCompute Metrics: Tracks objectives, times, and gaps\nSave Results: Outputs to JSON file","category":"page"},{"location":"tutorials/testing.html#Test-Configuration","page":"Inference & Evaluation","title":"Test Configuration","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"The test script uses these default settings:","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Iterations: 100 (can be changed via maxIT parameter in code)\nProximity parameter: 0.000001\nDevice: CPU only\nExact gradients: Enabled\nInstance features: Enabled","category":"page"},{"location":"tutorials/testing.html#Understanding-Test-Results","page":"Inference & Evaluation","title":"Understanding Test Results","text":"","category":"section"},{"location":"tutorials/testing.html#Output-File-Structure","page":"Inference & Evaluation","title":"Output File Structure","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"File: res_test2_<dataset_name>.json","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"{\n  \"instance1.dat\": {\n    \"time\": 1.234,\n    \"objs\": [0.0, 100.5, 150.3, ..., 245.8],\n    \"times\": [0.01, 0.02, 0.03, ..., 1.23],\n    \"gaps\": [100.0, 15.2, 5.3, ..., 1.2]\n  },\n  \"instance2.dat\": { ... }\n}","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Fields:","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"time: Total solving time (seconds)\nobjs: Objective value at each iteration\ntimes: Cumulative time at each iteration\ngaps: Optimality gap at each iteration (%)","category":"page"},{"location":"tutorials/testing.html#Analyzing-Results","page":"Inference & Evaluation","title":"Analyzing Results","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"using JSON\nusing Statistics\n\n# Load results\nresults = JSON.parsefile(\"res_test2_MCNDforTest.json\")\n\n# Compute statistics across all instances\nfinal_gaps = [data[\"gaps\"][end] for (inst, data) in results]\nfinal_times = [data[\"time\"] for (inst, data) in results]\nfinal_objs = [data[\"objs\"][end] for (inst, data) in results]\n\nprintln(\"Mean final gap: $(mean(final_gaps))%\")\nprintln(\"Median final gap: $(median(final_gaps))%\")\nprintln(\"Mean solving time: $(mean(final_times))s\")\n\n# Find best/worst instances\nsorted_gaps = sort(collect(results), by=x->x[2][\"gaps\"][end])\nprintln(\"Best instance: $(sorted_gaps[1][1])\")\nprintln(\"Worst instance: $(sorted_gaps[end][1])\")","category":"page"},{"location":"tutorials/testing.html#Visualization","page":"Inference & Evaluation","title":"Visualization","text":"","category":"section"},{"location":"tutorials/testing.html#Plot-Convergence","page":"Inference & Evaluation","title":"Plot Convergence","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"using Plots\n\n# Load results\nresults = JSON.parsefile(\"res_test2_MCNDforTest.json\")\n\n# Plot single instance\ninstance_name = \"instance1.dat\"\ndata = results[instance_name]\n\nplot(data[\"objs\"], \n     xlabel=\"Iteration\", \n     ylabel=\"Objective Value\",\n     title=\"Convergence: $instance_name\",\n     legend=false)","category":"page"},{"location":"tutorials/testing.html#Plot-Gaps-Over-Time","page":"Inference & Evaluation","title":"Plot Gaps Over Time","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"plot(data[\"gaps\"],\n     xlabel=\"Iteration\",\n     ylabel=\"Optimality Gap (%)\",\n     title=\"Gap Convergence\",\n     yscale=:log10,\n     legend=false)","category":"page"},{"location":"tutorials/testing.html#Compare-Multiple-Instances","page":"Inference & Evaluation","title":"Compare Multiple Instances","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"p = plot(xlabel=\"Iteration\", ylabel=\"Gap (%)\", \n         title=\"Gap Convergence\", yscale=:log10)\n\nfor (inst, data) in results\n    plot!(p, data[\"gaps\"], alpha=0.3, label=inst)\nend\n\nplot!(p)","category":"page"},{"location":"tutorials/testing.html#Comparing-Models","page":"Inference & Evaluation","title":"Comparing Models","text":"","category":"section"},{"location":"tutorials/testing.html#Test-Multiple-Models","page":"Inference & Evaluation","title":"Test Multiple Models","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"# Test model 1\njulia test.jl --data ./data/ --model ./resLogs/model1/ --dataset ./resLogs/model1/\n\n# Test model 2\njulia test.jl --data ./data/ --model ./resLogs/model2/ --dataset ./resLogs/model2/","category":"page"},{"location":"tutorials/testing.html#Compare-Results","page":"Inference & Evaluation","title":"Compare Results","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"using JSON, Statistics\n\n# Load both results\nres1 = JSON.parsefile(\"res_test2_model1.json\")\nres2 = JSON.parsefile(\"res_test2_model2.json\")\n\n# Compare final gaps\ngaps1 = [data[\"gaps\"][end] for (_, data) in res1]\ngaps2 = [data[\"gaps\"][end] for (_, data) in res2]\n\nprintln(\"Model 1 mean gap: $(mean(gaps1))%\")\nprintln(\"Model 2 mean gap: $(mean(gaps2))%\")\nprintln(\"Improvement: $(mean(gaps1) - mean(gaps2))%\")\n\n# Statistical test\nusing HypothesisTests\nt_test = OneSampleTTest(gaps1 .- gaps2)\nprintln(t_test)","category":"page"},{"location":"tutorials/testing.html#Advanced:-Custom-Testing","page":"Inference & Evaluation","title":"Advanced: Custom Testing","text":"","category":"section"},{"location":"tutorials/testing.html#Modify-Test-Parameters","page":"Inference & Evaluation","title":"Modify Test Parameters","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Edit test.jl to change:","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"# Change number of iterations\nmaxIT = 200  # Instead of default 100\n\n# Change proximity parameter\nt = 0.00001  # Instead of default 0.000001\n\n# Disable instance features\ninstance_features = false","category":"page"},{"location":"tutorials/testing.html#Test-on-Custom-Dataset","page":"Inference & Evaluation","title":"Test on Custom Dataset","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"# Create custom test set\ncustom_test = [\"instance1.dat\", \"instance5.dat\", \"instance10.dat\"]\n\n# Modify test.jl or create dataset.json:\ndataset = Dict(\"test\" => custom_test)","category":"page"},{"location":"tutorials/testing.html#Performance-Benchmarking","page":"Inference & Evaluation","title":"Performance Benchmarking","text":"","category":"section"},{"location":"tutorials/testing.html#Against-Baseline","page":"Inference & Evaluation","title":"Against Baseline","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Compare against standard bundle method:","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"# Test with NN guidance\njulia test.jl --data ./data/ --model ./resLogs/trained_model/ ...\n\n# Test with constant t (baseline)\n# Modify test.jl to use constant t_strat instead of nn_t_strategy()","category":"page"},{"location":"tutorials/testing.html#Metrics-to-Report","page":"Inference & Evaluation","title":"Metrics to Report","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Final Gap: Optimality at termination\nTime to 5% Gap: Iterations needed\nTotal Time: Computational cost\nSuccess Rate: % instances below target gap","category":"page"},{"location":"tutorials/testing.html#Troubleshooting","page":"Inference & Evaluation","title":"Troubleshooting","text":"","category":"section"},{"location":"tutorials/testing.html#Model-Not-Found","page":"Inference & Evaluation","title":"Model Not Found","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"ERROR: SystemError: opening file \"nn_bestLV.bson\": No such file","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Solution: Check model path and ensure nn_bestLV.bson exists.","category":"page"},{"location":"tutorials/testing.html#Gold-Solutions-Missing","page":"Inference & Evaluation","title":"Gold Solutions Missing","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"If using .dat format, ensure:","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"./golds/<dataset_name>/gold.json","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"exists with format:","category":"page"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"{\n  \"instance1.dat\": optimal_value,\n  ...\n}","category":"page"},{"location":"tutorials/testing.html#Out-of-Memory","page":"Inference & Evaluation","title":"Out of Memory","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Reduce batch size in test (currently always 1) or test fewer instances.","category":"page"},{"location":"tutorials/testing.html#Next-Steps","page":"Inference & Evaluation","title":"Next Steps","text":"","category":"section"},{"location":"tutorials/testing.html","page":"Inference & Evaluation","title":"Inference & Evaluation","text":"Return to Batch Training or Episodic Training\nSee Troubleshooting for common issues\nExplore API Reference for function details","category":"page"},{"location":"installation.html#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation.html#Prerequisites","page":"Installation","title":"Prerequisites","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Julia 1.9 or higher\n(Optional) CUDA-compatible GPU for acceleration","category":"page"},{"location":"installation.html#Installing-Julia","page":"Installation","title":"Installing Julia","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Download Julia from julialang.org","category":"page"},{"location":"installation.html#Linux/macOS","page":"Installation","title":"Linux/macOS","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"wget https://julialang-s3.julialang.org/bin/linux/x64/1.9/julia-1.9.4-linux-x86_64.tar.gz\ntar zxvf julia-1.9.4-linux-x86_64.tar.gz\nexport PATH=\"$PATH:$PWD/julia-1.9.4/bin\"","category":"page"},{"location":"installation.html#Windows","page":"Installation","title":"Windows","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Download and run the installer from the Julia website.","category":"page"},{"location":"installation.html#Installing-BundleNetworks","page":"Installation","title":"Installing BundleNetworks","text":"","category":"section"},{"location":"installation.html#Option-1:-Clone-from-GitHub","page":"Installation","title":"Option 1: Clone from GitHub","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"git clone https://github.com/yourusername/BundleNetworks.jl.git\ncd BundleNetworks.jl","category":"page"},{"location":"installation.html#Option-2:-Julia-Package-Manager-(if-registered)","page":"Installation","title":"Option 2: Julia Package Manager (if registered)","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"using Pkg\nPkg.add(\"BundleNetworks\")","category":"page"},{"location":"installation.html#Dependencies","page":"Installation","title":"Dependencies","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Install required packages:","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"using Pkg\n\n# Core dependencies\nPkg.add([\n    \"BundleNetworks\",\n    \"Instances\", \n    \"Flux\",\n    \"Zygote\",\n    \"LinearAlgebra\",\n    \"Statistics\",\n])\n\n# Optional: GPU support\nPkg.add(\"CUDA\")\n\n# Utilities\nPkg.add([\n    \"JSON\",\n    \"BSON\",\n    \"ArgParse\",\n    \"Random\",\n])\n\n# Logging and visualization\nPkg.add([\n    \"TensorBoardLogger\",\n    \"Logging\",\n])\n\n# Training utilities\nPkg.add([\n    \"MLUtils\",\n    \"ParameterSchedulers\",\n    \"ChainRules\",\n    \"ChainRulesCore\",\n])","category":"page"},{"location":"installation.html#Verifying-Installation","page":"Installation","title":"Verifying Installation","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"using BundleNetworks\nusing Flux\nusing CUDA\n\n# Check CUDA availability\nCUDA.functional()  # Should return true if GPU is available\n\n# Check BundleNetworks\nprintln(\"BundleNetworks loaded successfully!\")","category":"page"},{"location":"installation.html#Setting-Up-Data","page":"Installation","title":"Setting Up Data","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Create data directories:","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"mkdir -p data\nmkdir -p golds\nmkdir -p resLogs","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Download or generate problem instances\nCreate gold solutions file (if using .dat format):","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"mkdir -p golds/MCNDforTest\n# Add your gold.json file","category":"page"},{"location":"installation.html#Next-Steps","page":"Installation","title":"Next Steps","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"See Quick Start for your first training run\nExplore Tutorials for detailed examples","category":"page"},{"location":"tutorials/batch_training.html#Batch-Training-Tutorial","page":"Batch Training","title":"Batch Training Tutorial","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"This tutorial covers batch training mode, where multiple instances are processed  together for more stable gradient estimates.","category":"page"},{"location":"tutorials/batch_training.html#When-to-Use-Batch-Training","page":"Batch Training","title":"When to Use Batch Training","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Use batch training when:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"You have sufficient memory (GPU/CPU)\nInstances are similar in size and structure\nYou want more stable gradients\nTraining time is not critical","category":"page"},{"location":"tutorials/batch_training.html#Basic-Batch-Training","page":"Batch Training","title":"Basic Batch Training","text":"","category":"section"},{"location":"tutorials/batch_training.html#Minimal-Example","page":"Batch Training","title":"Minimal Example","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"julia runs/train_batch.jl \\\n  --data ./data/MCNDforTest/ \\\n  --lr 0.001 \\\n  --mti 100 \\\n  --mvi 20 \\\n  --seed 42 \\\n  --maxItBack 50 \\\n  --maxEP 100 \\\n  --batch_size 4","category":"page"},{"location":"tutorials/batch_training.html#Understanding-Batch-Size","page":"Batch Training","title":"Understanding Batch Size","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Batch Size 1 (Default):","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Processes one instance at a time\nLower memory usage\nHigher gradient variance\nFaster iterations","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Batch Size 4-8:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Processes multiple instances together\nMore stable gradients\nHigher memory usage\nSlower iterations but better convergence","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Choosing Batch Size:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"# Memory-constrained\n--batch_size 1\n\n# Balanced\n--batch_size 4\n\n# High-memory system\n--batch_size 8","category":"page"},{"location":"tutorials/batch_training.html#Advanced-Configuration","page":"Batch Training","title":"Advanced Configuration","text":"","category":"section"},{"location":"tutorials/batch_training.html#Curriculum-Learning","page":"Batch Training","title":"Curriculum Learning","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Gradually increase difficulty by starting with fewer iterations:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"julia runs/train_batch.jl \\\n  --incremental true \\\n  --maxIt 100 \\\n  --maxEP 100 \\\n  ...","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"How it works:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Epochs 1-50: Linearly increase from 2 iterations to 100\nEpochs 51-100: Use full 100 iterations","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Benefits:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Easier optimization early in training\nHelps avoid local minima\nCan improve final performance","category":"page"},{"location":"tutorials/batch_training.html#Loss-Functions","page":"Batch Training","title":"Loss Functions","text":"","category":"section"},{"location":"tutorials/batch_training.html#Standard-Loss","page":"Batch Training","title":"Standard Loss","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"--lambda 0.0 --gamma 0.0","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Loss = -ϕ(x_final)","category":"page"},{"location":"tutorials/batch_training.html#Weighted-Loss","page":"Batch Training","title":"Weighted Loss","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"--lambda 0.5","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Loss = -[0.5 * ϕ(xfinal) + 0.5 * ϕ(xstabilization)]","category":"page"},{"location":"tutorials/batch_training.html#Telescopic-Loss","page":"Batch Training","title":"Telescopic Loss","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"--gamma 0.1","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Loss = -Σ γ^i * ϕ(x_i)","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Recommendation: Start with standard loss, add telescopic if underfitting.","category":"page"},{"location":"tutorials/batch_training.html#Architecture-Options","page":"Batch Training","title":"Architecture Options","text":"","category":"section"},{"location":"tutorials/batch_training.html#Hidden-Size","page":"Batch Training","title":"Hidden Size","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"--h_representation 64   # Default, good balance\n--h_representation 32   # Faster, less capacity\n--h_representation 128  # Slower, more capacity","category":"page"},{"location":"tutorials/batch_training.html#Activation-Functions","page":"Batch Training","title":"Activation Functions","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"--h_act softplus  # Smooth, default\n--h_act relu      # Sparse, faster\n--h_act tanh      # Bounded\n--h_act gelu      # Smooth, modern","category":"page"},{"location":"tutorials/batch_training.html#Sampling-Strategies","page":"Batch Training","title":"Sampling Strategies","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"# Sample proximity parameter\n--sampling_t true\n\n# Sample in latent space for attention\n--sampling_gamma true","category":"page"},{"location":"tutorials/batch_training.html#Optimization-Settings","page":"Batch Training","title":"Optimization Settings","text":"","category":"section"},{"location":"tutorials/batch_training.html#Learning-Rate-Schedule","page":"Batch Training","title":"Learning Rate Schedule","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"--lr 0.001          # Initial learning rate\n--decay 0.9         # Decay factor\n--scheduling_ss 100 # Apply decay every 100 epochs","category":"page"},{"location":"tutorials/batch_training.html#Gradient-Clipping","page":"Batch Training","title":"Gradient Clipping","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"--cn 5   # Clip gradient norm to 5 (default)\n--cn 10  # More lenient clipping","category":"page"},{"location":"tutorials/batch_training.html#Complete-Example","page":"Batch Training","title":"Complete Example","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"julia runs/train_batch.jl \\\n  --data ./data/MCNDforTest/ \\\n  --lr 0.001 \\\n  --decay 0.95 \\\n  --cn 5 \\\n  --mti 200 \\\n  --mvi 40 \\\n  --seed 42 \\\n  --maxItBack 50 \\\n  --maxIt 100 \\\n  --maxItVal 200 \\\n  --maxEP 150 \\\n  --batch_size 4 \\\n  --incremental true \\\n  --h_representation 64 \\\n  --h_act softplus \\\n  --use_softmax true \\\n  --sampling_t true \\\n  --sampling_gamma false \\\n  --gamma 0.05 \\\n  --lambda 0.0 \\\n  --scheduling_ss 50","category":"page"},{"location":"tutorials/batch_training.html#Monitoring-Training","page":"Batch Training","title":"Monitoring Training","text":"","category":"section"},{"location":"tutorials/batch_training.html#Console-Output","page":"Batch Training","title":"Console Output","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Epoch 1 Training - lsp: 1234.56  gap: 15.2%\nEpoch 1 Validation - lsp: 1250.30  gap: 12.8%","category":"page"},{"location":"tutorials/batch_training.html#TensorBoard","page":"Batch Training","title":"TensorBoard","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"tensorboard --logdir resLogs/","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Key Plots:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Train/GAP_percentage: Training gap over time\nValidation/GAP_percentage: Validation gap\nTrain/Loss_value: Training loss","category":"page"},{"location":"tutorials/batch_training.html#Interpreting-Results","page":"Batch Training","title":"Interpreting Results","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Good Training:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Training gap decreases steadily\nValidation gap tracks training gap\nLoss decreases (becomes more negative)","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Overfitting:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Training gap << Validation gap\nValidation gap stops improving","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Underfitting:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Both gaps remain high\nLoss plateaus early","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Solutions:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Overfitting: Reduce model size, add regularization (gamma)\nUnderfitting: Increase model size, train longer","category":"page"},{"location":"tutorials/batch_training.html#Output-Files","page":"Batch Training","title":"Output Files","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"After training, find in resLogs/<experiment_name>/:","category":"page"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"nn.bson: Final model\nnn_best.bson: Best validation model\nloss.json: Loss per epoch\ngaps.json: Training gaps\ngaps_val.json: Validation gaps\ndataset.json: Train/val split","category":"page"},{"location":"tutorials/batch_training.html#Next-Steps","page":"Batch Training","title":"Next Steps","text":"","category":"section"},{"location":"tutorials/batch_training.html","page":"Batch Training","title":"Batch Training","text":"Try Episodic Training for comparison\nLearn about Testing your model\nExplore Hyperparameter Tuning","category":"page"},{"location":"tutorials/tesing.html#Testing-and-Evaluation-Tutorial","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Learn how to evaluate trained models on test instances.","category":"page"},{"location":"tutorials/tesing.html#Basic-Testing","page":"Testing & Evaluation Tutorial","title":"Basic Testing","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"julia runs/test.jl \\\n  --data ./data/MCNDforTest/ \\\n  --model ./resLogs/BatchVersion_bs_1_seed42_.../ \\\n  --dataset ./resLogs/BatchVersion_bs_1_seed42_.../","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Arguments:","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"--data: Path to instance folder\n--model: Path to folder containing trained model (nnbestLV.bson or nnbest.bson)\n--dataset: Path to folder containing dataset.json","category":"page"},{"location":"tutorials/tesing.html#What-the-Test-Script-Does","page":"Testing & Evaluation Tutorial","title":"What the Test Script Does","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Load Model: Reads trained neural network from BSON file\nLoad Test Split: Reads test instance list from dataset.json\nLoad Instances: Processes each test instance\nRun Bundle Method: Solves with NN guidance for 100 iterations (default)\nCompute Metrics: Tracks objectives, times, and gaps\nSave Results: Outputs to JSON file","category":"page"},{"location":"tutorials/tesing.html#Test-Configuration","page":"Testing & Evaluation Tutorial","title":"Test Configuration","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"The test script uses these default settings:","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Iterations: 100 (can be changed via maxIT parameter in code)\nProximity parameter: 0.000001\nDevice: CPU only\nExact gradients: Enabled\nInstance features: Enabled","category":"page"},{"location":"tutorials/tesing.html#Understanding-Test-Results","page":"Testing & Evaluation Tutorial","title":"Understanding Test Results","text":"","category":"section"},{"location":"tutorials/tesing.html#Output-File-Structure","page":"Testing & Evaluation Tutorial","title":"Output File Structure","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"File: res_test2_<dataset_name>.json","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"{\n  \"instance1.dat\": {\n    \"time\": 1.234,\n    \"objs\": [0.0, 100.5, 150.3, ..., 245.8],\n    \"times\": [0.01, 0.02, 0.03, ..., 1.23],\n    \"gaps\": [100.0, 15.2, 5.3, ..., 1.2]\n  },\n  \"instance2.dat\": { ... }\n}","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Fields:","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"time: Total solving time (seconds)\nobjs: Objective value at each iteration\ntimes: Cumulative time at each iteration\ngaps: Optimality gap at each iteration (%)","category":"page"},{"location":"tutorials/tesing.html#Analyzing-Results","page":"Testing & Evaluation Tutorial","title":"Analyzing Results","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"using JSON\nusing Statistics\n\n# Load results\nresults = JSON.parsefile(\"res_test2_MCNDforTest.json\")\n\n# Compute statistics across all instances\nfinal_gaps = [data[\"gaps\"][end] for (inst, data) in results]\nfinal_times = [data[\"time\"] for (inst, data) in results]\nfinal_objs = [data[\"objs\"][end] for (inst, data) in results]\n\nprintln(\"Mean final gap: $(mean(final_gaps))%\")\nprintln(\"Median final gap: $(median(final_gaps))%\")\nprintln(\"Mean solving time: $(mean(final_times))s\")\n\n# Find best/worst instances\nsorted_gaps = sort(collect(results), by=x->x[2][\"gaps\"][end])\nprintln(\"Best instance: $(sorted_gaps[1][1])\")\nprintln(\"Worst instance: $(sorted_gaps[end][1])\")","category":"page"},{"location":"tutorials/tesing.html#Visualization","page":"Testing & Evaluation Tutorial","title":"Visualization","text":"","category":"section"},{"location":"tutorials/tesing.html#Plot-Convergence","page":"Testing & Evaluation Tutorial","title":"Plot Convergence","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"using Plots\n\n# Load results\nresults = JSON.parsefile(\"res_test2_MCNDforTest.json\")\n\n# Plot single instance\ninstance_name = \"instance1.dat\"\ndata = results[instance_name]\n\nplot(data[\"objs\"], \n     xlabel=\"Iteration\", \n     ylabel=\"Objective Value\",\n     title=\"Convergence: $instance_name\",\n     legend=false)","category":"page"},{"location":"tutorials/tesing.html#Plot-Gaps-Over-Time","page":"Testing & Evaluation Tutorial","title":"Plot Gaps Over Time","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"plot(data[\"gaps\"],\n     xlabel=\"Iteration\",\n     ylabel=\"Optimality Gap (%)\",\n     title=\"Gap Convergence\",\n     yscale=:log10,\n     legend=false)","category":"page"},{"location":"tutorials/tesing.html#Compare-Multiple-Instances","page":"Testing & Evaluation Tutorial","title":"Compare Multiple Instances","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"p = plot(xlabel=\"Iteration\", ylabel=\"Gap (%)\", \n         title=\"Gap Convergence\", yscale=:log10)\n\nfor (inst, data) in results\n    plot!(p, data[\"gaps\"], alpha=0.3, label=inst)\nend\n\nplot!(p)","category":"page"},{"location":"tutorials/tesing.html#Comparing-Models","page":"Testing & Evaluation Tutorial","title":"Comparing Models","text":"","category":"section"},{"location":"tutorials/tesing.html#Test-Multiple-Models","page":"Testing & Evaluation Tutorial","title":"Test Multiple Models","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"# Test model 1\njulia test.jl --data ./data/ --model ./resLogs/model1/ --dataset ./resLogs/model1/\n\n# Test model 2\njulia test.jl --data ./data/ --model ./resLogs/model2/ --dataset ./resLogs/model2/","category":"page"},{"location":"tutorials/tesing.html#Compare-Results","page":"Testing & Evaluation Tutorial","title":"Compare Results","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"using JSON, Statistics\n\n# Load both results\nres1 = JSON.parsefile(\"res_test2_model1.json\")\nres2 = JSON.parsefile(\"res_test2_model2.json\")\n\n# Compare final gaps\ngaps1 = [data[\"gaps\"][end] for (_, data) in res1]\ngaps2 = [data[\"gaps\"][end] for (_, data) in res2]\n\nprintln(\"Model 1 mean gap: $(mean(gaps1))%\")\nprintln(\"Model 2 mean gap: $(mean(gaps2))%\")\nprintln(\"Improvement: $(mean(gaps1) - mean(gaps2))%\")\n\n# Statistical test\nusing HypothesisTests\nt_test = OneSampleTTest(gaps1 .- gaps2)\nprintln(t_test)","category":"page"},{"location":"tutorials/tesing.html#Advanced:-Custom-Testing","page":"Testing & Evaluation Tutorial","title":"Advanced: Custom Testing","text":"","category":"section"},{"location":"tutorials/tesing.html#Modify-Test-Parameters","page":"Testing & Evaluation Tutorial","title":"Modify Test Parameters","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Edit test.jl to change:","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"# Change number of iterations\nmaxIT = 200  # Instead of default 100\n\n# Change proximity parameter\nt = 0.00001  # Instead of default 0.000001\n\n# Disable instance features\ninstance_features = false","category":"page"},{"location":"tutorials/tesing.html#Test-on-Custom-Dataset","page":"Testing & Evaluation Tutorial","title":"Test on Custom Dataset","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"# Create custom test set\ncustom_test = [\"instance1.dat\", \"instance5.dat\", \"instance10.dat\"]\n\n# Modify test.jl or create dataset.json:\ndataset = Dict(\"test\" => custom_test)","category":"page"},{"location":"tutorials/tesing.html#Performance-Benchmarking","page":"Testing & Evaluation Tutorial","title":"Performance Benchmarking","text":"","category":"section"},{"location":"tutorials/tesing.html#Against-Baseline","page":"Testing & Evaluation Tutorial","title":"Against Baseline","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Compare against standard bundle method:","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"# Test with NN guidance\njulia test.jl --data ./data/ --model ./resLogs/trained_model/ ...\n\n# Test with constant t (baseline)\n# Modify test.jl to use constant t_strat instead of nn_t_strategy()","category":"page"},{"location":"tutorials/tesing.html#Metrics-to-Report","page":"Testing & Evaluation Tutorial","title":"Metrics to Report","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Final Gap: Optimality at termination\nTime to 5% Gap: Iterations needed\nTotal Time: Computational cost\nSuccess Rate: % instances below target gap","category":"page"},{"location":"tutorials/tesing.html#Troubleshooting","page":"Testing & Evaluation Tutorial","title":"Troubleshooting","text":"","category":"section"},{"location":"tutorials/tesing.html#Model-Not-Found","page":"Testing & Evaluation Tutorial","title":"Model Not Found","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"ERROR: SystemError: opening file \"nn_bestLV.bson\": No such file","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Solution: Check model path and ensure nn_bestLV.bson exists.","category":"page"},{"location":"tutorials/tesing.html#Gold-Solutions-Missing","page":"Testing & Evaluation Tutorial","title":"Gold Solutions Missing","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"If using .dat format, ensure:","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"./golds/<dataset_name>/gold.json","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"exists with format:","category":"page"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"{\n  \"instance1.dat\": optimal_value,\n  ...\n}","category":"page"},{"location":"tutorials/tesing.html#Out-of-Memory","page":"Testing & Evaluation Tutorial","title":"Out of Memory","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Reduce batch size in test (currently always 1) or test fewer instances.","category":"page"},{"location":"tutorials/tesing.html#Next-Steps","page":"Testing & Evaluation Tutorial","title":"Next Steps","text":"","category":"section"},{"location":"tutorials/tesing.html","page":"Testing & Evaluation Tutorial","title":"Testing & Evaluation Tutorial","text":"Return to Batch Training or Episodic Training\nSee Troubleshooting for common issues\nExplore API Reference for function details","category":"page"},{"location":"index.html#BundleNetworks.jl-Documentation","page":"Home","title":"BundleNetworks.jl Documentation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Neural Network-Guided Bundle Methods for Non-Smooth Optimization","category":"page"},{"location":"index.html#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"BundleNetworks.jl implements a machine learning approach to accelerate bundle methods  by learning optimal hyperparameters from training data. The neural network predicts  proximity parameters and gradient aggregation weights at each iteration, improving  convergence speed compared to traditional bundle methods.","category":"page"},{"location":"index.html#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Neural Network-Guided Optimization: Learn bundle method parameters using attention mechanisms\nFlexible Training: Batch and episodic training modes\nCurriculum Learning: Gradually increase problem difficulty\nComprehensive Evaluation: Training, validation, and test tracking with TensorBoard integration\nGPU Support: Optional CUDA acceleration","category":"page"},{"location":"index.html#Quick-Example","page":"Home","title":"Quick Example","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"# Train a model\njulia train_batch.jl \\\n  --data ./data/MCNDforTest/ \\\n  --lr 0.001 \\\n  --mti 100 \\\n  --mvi 20 \\\n  --seed 42 \\\n  --maxItBack 50 \\\n  --maxEP 100\n\n# Test the model\njulia test.jl \\\n  --data ./data/MCNDforTest/ \\\n  --model ./resLogs/model_folder/ \\\n  --dataset ./resLogs/model_folder/","category":"page"},{"location":"index.html#Package-Contents","page":"Home","title":"Package Contents","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Pages = [\n    \"installation.md\",\n    \"quickstart.md\",\n]\nDepth = 2","category":"page"},{"location":"index.html#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Pages = [\n    \"manual/architecture.md\",\n    \"manual/bundle_methods.md\",\n    \"manual/data_formats.md\",\n]\nDepth = 1","category":"page"},{"location":"index.html#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"","category":"page"}]
}
