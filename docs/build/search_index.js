var documenterSearchIndex = {"docs":
[{"location":"tutorials/baselines.html#Baselines","page":"Baselines","title":"Baselines","text":"","category":"section"},{"location":"tutorials/baselines.html","page":"Baselines","title":"Baselines","text":"To compare our approaches with other existing methods, we propose several baselines:","category":"page"},{"location":"tutorials/baselines.html","page":"Baselines","title":"Baselines","text":"The classic bundle method with heuristic strategies to tune the regularization parameter. Further details can be found: https://lipn.univ-paris13.fr/~demelas/Manuscript_Final.pdf\nA Flux implementation of the classic gradient descent.\nA Flux implementation of Adam optimizer.","category":"page"},{"location":"tutorials/baselines.html","page":"Baselines","title":"Baselines","text":"For each baseline, we consider an initial (step-size/regularization) parameter obtained through a grid search, and we save all the results in a JSON file.","category":"page"},{"location":"tutorials/baselines.html","page":"Baselines","title":"Baselines","text":"Assuming that you have already downloaded or created your data and saved it in ./data/<your_folder>/, you can run the baselines as:","category":"page"},{"location":"tutorials/baselines.html","page":"Baselines","title":"Baselines","text":"julia --project=. ./runs/runBaselines.jl --folder ./data/<your_folder>/ --maxIterDescentType 1000 --maxIterBundle 100 --TS 0.01 0.1 1.0 1 10 100 1000","category":"page"},{"location":"tutorials/baselines.html#Parameters-Explanation","page":"Baselines","title":"Parameters Explanation","text":"","category":"section"},{"location":"tutorials/baselines.html","page":"Baselines","title":"Baselines","text":"--folder ./data/<your_folder>/: The folder containing your data.\n--maxIterDescentType 1000: The maximum number of iterations for Adam and Descent.\n--maxIterBundle 100: The maximum number of iterations for the Bundle methods.\n--TS 0.01 0.1 1.0 1 10 100 1000: The initial parameters to consider in the grid search.","category":"page"},{"location":"tutorials/baselines.html#Further-References","page":"Baselines","title":"Further References","text":"","category":"section"},{"location":"tutorials/baselines.html","page":"Baselines","title":"Baselines","text":"Bundle Network: A fully ML-based Bundle Method.\nHyper-Parameter Learning: Learning an hyper-parameter in the (aggregated) Bundle method.","category":"page"},{"location":"manual/architecture.html#Neural-Network-Architecture","page":"Architecture","title":"Neural Network Architecture","text":"","category":"section"},{"location":"manual/architecture.html#Overview","page":"Architecture","title":"Overview","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"The neural network architecture is designed to predict bundle method parameters  from the current optimization state.","category":"page"},{"location":"manual/architecture.html#Model-Components","page":"Architecture","title":"Model Components","text":"","category":"section"},{"location":"manual/architecture.html#Encoder","page":"Architecture","title":"Encoder","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Processes instance features and bundle state:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Input Features → Linear → Activation → Linear → Hidden Representation","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Input features include:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Bundle gradients (subgradients)\nFunction values\nDual variables (optional: from CR)\nInstance structure (optional: graph features)","category":"page"},{"location":"manual/architecture.html#Decoder-for-Proximity-Parameter-(t)","page":"Architecture","title":"Decoder for Proximity Parameter (t)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Predicts the proximity parameter:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Hidden Representation → Linear → Softplus → t","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Output: Scalar proximity parameter controlling trust region size.","category":"page"},{"location":"manual/architecture.html#Decoder-for-Gradient-Aggregation-(γ)","page":"Architecture","title":"Decoder for Gradient Aggregation (γ)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Predicts weights for convex combination of gradients:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Hidden Representation → Attention → Distribution → θ","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Components:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Query Network: Generates query from hidden state\nKey Network: Generates keys from bundle components\nAttention Mechanism: Computes attention scores\nDistribution: Softmax or Sparsemax normalization","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Output: Probability distribution over bundle components.","category":"page"},{"location":"manual/architecture.html#Attention-Mechanism","page":"Architecture","title":"Attention Mechanism","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"The attention mechanism computes how to aggregate bundle gradients:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Q = QueryNetwork(hidden_state)\nK = KeyNetwork(bundle_gradients)\nV = bundle_gradients\n\nscores = Q · K^T\nθ = softmax(scores)\naggregated_gradient = Σ θ_i * V_i","category":"page"},{"location":"manual/architecture.html#Architecture-Variants","page":"Architecture","title":"Architecture Variants","text":"","category":"section"},{"location":"manual/architecture.html#Standard-Architecture-(h3false)","page":"Architecture","title":"Standard Architecture (h3=false)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Three separate hidden representations:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"One for proximity parameter\nOne for attention queries\nOne for attention keys","category":"page"},{"location":"manual/architecture.html#Compact-Architecture-(h3true)","page":"Architecture","title":"Compact Architecture (h3=true)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Single shared hidden representation for all outputs.","category":"page"},{"location":"manual/architecture.html#Model-Factory","page":"Architecture","title":"Model Factory","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Models are created via factories:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"factory = BundleNetworks.AttentionModelFactory()\nnn = BundleNetworks.create_NN(\n    factory;\n    h_representation=64,\n    h_act=softplus,\n    sampling_θ=false,\n    sampling_t=true\n)","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Parameters:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"h_representation: Hidden layer size\nh_act: Activation function\nsampling_θ: Sample attention weights\nsampling_t: Sample proximity parameter","category":"page"},{"location":"manual/architecture.html#Sampling-Strategies","page":"Architecture","title":"Sampling Strategies","text":"","category":"section"},{"location":"manual/architecture.html#Deterministic-(Default-for-Testing)","page":"Architecture","title":"Deterministic (Default for Testing)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"nn.sample_t = false\nnn.sample_γ = false","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Outputs are mean predictions.","category":"page"},{"location":"manual/architecture.html#Stochastic-(Training)","page":"Architecture","title":"Stochastic (Training)","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"nn.sample_t = true\nnn.sample_γ = true","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Samples from learned distributions for exploration.","category":"page"},{"location":"manual/architecture.html#Graph-Features","page":"Architecture","title":"Graph Features","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"When use_graph=true, bipartite graph features are extracted:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Instance → Bipartite Graph → Graph Convolution → Features","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"This captures:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Variable-constraint relationships\nNetwork structure\nSparsity patterns","category":"page"},{"location":"manual/architecture.html#Activation-Functions","page":"Architecture","title":"Activation Functions","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Supported activations:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"softplus: Smooth, always positive (good for t)\nrelu: Sparse, fast\ntanh: Bounded, smooth\ngelu: Modern, smooth","category":"page"},{"location":"manual/architecture.html#Parameter-Count","page":"Architecture","title":"Parameter Count","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"Typical model sizes:","category":"page"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"h_representation Parameters\n32 ~10K\n64 ~40K\n128 ~160K","category":"page"},{"location":"manual/architecture.html#Next-Steps","page":"Architecture","title":"Next Steps","text":"","category":"section"},{"location":"manual/architecture.html","page":"Architecture","title":"Architecture","text":"See Bundle Methods for algorithm details\nLearn about Loss Functions\nExplore Hyperparameter Tuning","category":"page"},{"location":"quickstart.html#Quick-Start-Guide","page":"Quick Start","title":"Quick Start Guide","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"This guide will help you train and test your first model in under 5 minutes.","category":"page"},{"location":"quickstart.html#Step-1:-Prepare-Your-Data","page":"Quick Start","title":"Step 1: Prepare Your Data","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Ensure you have:","category":"page"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Problem instances in ./data/<your_folder>/\n(Optional) Gold solutions as json as ./golds/<your_folder>/gold.json","category":"page"},{"location":"quickstart.html#Step-2:-Train-a-Model","page":"Quick Start","title":"Step 2: Train a Model","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"We suggest to visit the other pages to have more informations about training routines:","category":"page"},{"location":"quickstart.html#Further-references","page":"Quick Start","title":"Further references","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"Bundle Network: A fully ML-based Bundle Method\nHyper-Parameter Learning: Learning an Hyper-parameter in the (aggregated) Bundle method\nBaselines: Grid-Search based baselines including: classic (aggregated) Bundle method with different t-strategies (tuning strategies for the regularization parameter), Adam and Descent.","category":"page"},{"location":"quickstart.html#Troubleshooting","page":"Quick Start","title":"Troubleshooting","text":"","category":"section"},{"location":"quickstart.html","page":"Quick Start","title":"Quick Start","text":"See Troubleshooting if you encounter issues.","category":"page"},{"location":"installation.html#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation.html#Prerequisites","page":"Installation","title":"Prerequisites","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Julia 1.9 or higher\n(Optional) CUDA-compatible GPU for acceleration","category":"page"},{"location":"installation.html#Installing-Julia","page":"Installation","title":"Installing Julia","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Download Julia from julialang.org","category":"page"},{"location":"installation.html#Linux/macOS","page":"Installation","title":"Linux/macOS","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"wget https://julialang-s3.julialang.org/bin/linux/x64/1.9/julia-1.9.4-linux-x86_64.tar.gz\ntar zxvf julia-1.9.4-linux-x86_64.tar.gz\nexport PATH=\"$PATH:$PWD/julia-1.9.4/bin\"","category":"page"},{"location":"installation.html#Windows","page":"Installation","title":"Windows","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Download and run the installer from the Julia website.","category":"page"},{"location":"installation.html#Installing-BundleNetworks","page":"Installation","title":"Installing BundleNetworks","text":"","category":"section"},{"location":"installation.html#Step-1:-Clone-from-GitHub","page":"Installation","title":"Step 1: Clone from GitHub","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"git clone git@github.com:FDemelas/bundlenetwork.jl.git\ncd bundlenetwork.jl","category":"page"},{"location":"installation.html#Step-2:-Julia-Package-Manager-(if-registered)","page":"Installation","title":"Step 2: Julia Package Manager (if registered)","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"# Use the package manager\nusing Pkg\n\n# Activate the project directory\nPkg.activate(\".\")\n\n# Install dependencies\nPkg.instantiate()","category":"page"},{"location":"installation.html#Verifying-Installation","page":"Installation","title":"Verifying Installation","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"using BundleNetworks\nusing Flux\nusing CUDA\n\n# Check CUDA availability\nCUDA.functional()  # Should return true if GPU is available\n\n# Confirm BundleNetworks loads successfully\nprintln(\"BundleNetworks loaded successfully!\")","category":"page"},{"location":"installation.html#Setting-Up-Data","page":"Installation","title":"Setting Up Data","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Create data directories:","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"mkdir -p data\nmkdir -p golds\nmkdir -p resLogs","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"Download or generate problem instances and place them in ./data/<your_folder>\nCreate gold solutions file in ./golds/<your_folder>. If the directory does not exist, create it:","category":"page"},{"location":"installation.html","page":"Installation","title":"Installation","text":"mkdir -p golds/<your_folder>\n# Add your gold.json file here","category":"page"},{"location":"installation.html#Next-Steps","page":"Installation","title":"Next Steps","text":"","category":"section"},{"location":"installation.html","page":"Installation","title":"Installation","text":"See Quick Start for your first training run\nExplore Tutorials for detailed examples","category":"page"},{"location":"tutorials/bundle_networks.html#Bundle-Network","page":"Bundle Network","title":"Bundle Network","text":"","category":"section"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"This methodology substitutes the resolution of the (Quadratic) Master Problem in the Bundle Method, computing the search direction as a convex combination of the sub-gradients at visited points, with an ML model based on Recursion and Attention.","category":"page"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"We assume that you have already downloaded or created your data and saved it in ./data/<your_folder>/.   This folder should contain 2000 instances, with 1000 used for training, 500 for validation, and 500 for testing.","category":"page"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"","category":"page"},{"location":"tutorials/bundle_networks.html#Training","page":"Bundle Network","title":"Training","text":"","category":"section"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"Here we demonstrate how to train such a model, with or without batching.","category":"page"},{"location":"tutorials/bundle_networks.html#Without-Batching","page":"Bundle Network","title":"Without Batching","text":"","category":"section"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"julia --project=. ./runs/runTraining.jl --data ./data/<your_folder>/ --lr 1.0e-4 --decay 0.9 --cn 5 --mti 1000 --mvi 500 --seed 1 --maxIt 10 --maxEP 10 --soft_updates true --h_representation 32 --use_softmax false --gamma 0.999 --lambda 0.0 --delta 0.0 --use_graph false --maxItBack -1 --maxItVal 20 --batch_size 2 --always_batch true --h_act softplus --sampling_gamma false","category":"page"},{"location":"tutorials/bundle_networks.html#Using-Batching","page":"Bundle Network","title":"Using Batching","text":"","category":"section"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"julia --project=. ./runs/runTraining.jl --data ./data/<your_folder>/ --lr 1.0e-4 --decay 0.9 --cn 5 --mti 100 --mvi 500 --seed 1 --maxIt 10 --maxEP 10 --soft_updates true --h_representation 32 --use_softmax false --gamma 0.999 --lambda 0.0 --delta 0.0 --use_graph false --maxItBack -1 --maxItVal 20 --batch_size 1 --always_batch true --h_act softplus --sampling_gamma false","category":"page"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"","category":"page"},{"location":"tutorials/bundle_networks.html#Parameter-Explanation","page":"Bundle Network","title":"Parameter Explanation","text":"","category":"section"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"--data ./data/<your_folder>/: Path to the folder containing the dataset instances.  \n--lr 1.0e-4: Learning rate for updating the model parameters.  \n--decay 0.9: Decay factor for the optimizer.  \n--cn 5: Coefficient to prevent the gradient norm from becoming too large.  \n--mti 1000: Number of training instances.  \n--mvi 500: Number of validation instances.  \n--seed 1: Random seed.  \n--maxIt 10: Number of iterations (unrolls) of the Bundle method per call.  \n--maxEP 10: Number of training epochs.  \n--soft_updates true: If false, uses the standard bundle strategy; if true, uses a smoothed update based on the softplus function.  \n--h_representation 32: Size of the hidden representation for each visited point.  \n--use_softmax false: If true, uses softmax to predict the convex combination coefficients; otherwise, uses sparsemax.  \n--gamma 0.999: Coefficient in the telescopic sum, larger for the last point, smaller for earlier points.  \n--lambda 0.0: Final contribution weight: lambda * final_point + (1 - lambda) * stabilization_point.  \n--delta 0.0: Additional regularization parameter.  \n--use_graph false: If true, uses a bipartite graph representation instead of recurrence (still in development; not recommended).  \n--maxItBack -1: (Description missing; please clarify if needed.)  \n--maxItVal 20: Number of iterations of the Bundle method for validation instances.  \n--batch_size 1: Batch size.  \n--sampling_gamma false: If true, uses sampling in the hidden representation; otherwise, no.  \n--always_batch true: If batch_size is 1 and this is true, batching is enforced anyway.  \n--h_act softplus: Activation function used in hidden layers.","category":"page"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"","category":"page"},{"location":"tutorials/bundle_networks.html#Testing","page":"Bundle Network","title":"Testing","text":"","category":"section"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"To evaluate a pretrained model's performance:","category":"page"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"julia --project=. ./runs/runTest.jl --folder ./data/<your_folder>/ --model_folder BatchVersion_bs_1_true_<your_folder>_0.0001_0.9_5_1000_500_1_10_100_true_32_false_softplus_false_0.999_0.0_0.0_sparsemax_false_false_1.0","category":"page"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"","category":"page"},{"location":"tutorials/bundle_networks.html#Parameters-Explanation","page":"Bundle Network","title":"Parameters Explanation","text":"","category":"section"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"--data ./data/<your_folder>/: Path to the dataset folder.  \n--dataset ./res/BatchVersion_bs_1_true_<your_folder>_0.0001_0.9_5_1000_500_1_10_100_true_32_false_softplus_false_0.999_0.0_0.0_sparsemax_false_false_1.0/: Path to the model folder, usually obtained from training.  \n--model: (Optional) Path to a specific model folder; if omitted, defaults to the associated test instances folder.","category":"page"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"","category":"page"},{"location":"tutorials/bundle_networks.html#Further-References","page":"Bundle Network","title":"Further References","text":"","category":"section"},{"location":"tutorials/bundle_networks.html","page":"Bundle Network","title":"Bundle Network","text":"Hyper-Parameter Learning: Learning hyperparameters in the (aggregated) Bundle method.  \nBaselines: Grid-search based baselines, including classic (aggregated) Bundle methods with various strategies, Adam, and Gradient Descent.","category":"page"},{"location":"index.html#BundleNetworks.jl-Documentation","page":"Home","title":"BundleNetworks.jl Documentation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Neural Network-Guided Bundle Methods for Non-Smooth Optimization","category":"page"},{"location":"index.html#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"BundleNetworks.jl implements:","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"A machine learning approach to accelerate bundle methods by learning optimal hyperparameters from training data.\nA machine learning-based unrolling model that predicts the coefficients of the convex combination of gradients (considered as step size), as well as the step size itself.","category":"page"},{"location":"index.html#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Neural Network-Guided Optimization: Learn bundle method parameters using attention mechanisms.\nFlexible Training: Supports batch and episodic training modes.\nCurriculum Learning: Gradually increases problem difficulty.\nComprehensive Evaluation: Tracks training, validation, and testing metrics with TensorBoard integration.\nGPU Support: Optional CUDA acceleration.","category":"page"},{"location":"index.html#Quick-Example","page":"Home","title":"Quick Example","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"# Train a model\njulia runTraining.jl \\\n  --data ./data/<your_folder>/ \\\n  --lr 0.001 \\\n  --mti 100 \\\n  --mvi 20 \\\n  --seed 42 \\\n  --maxItBack 50 \\\n  --maxEP 100\n\n# Test the model\njulia runTest.jl \\\n  --data ./data/<your_folder>/ \\\n  --model ./resLogs/model_folder/ \\\n  --dataset ./resLogs/model_folder/","category":"page"},{"location":"index.html#Package-Contents","page":"Home","title":"Package Contents","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Pages = [\n    \"installation.md\",\n    \"quickstart.md\",\n]\nDepth = 2","category":"page"},{"location":"index.html#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Pages = [\n    \"manual/architecture.md\",\n    \"manual/bundle_methods.md\",\n    \"manual/data_formats.md\",\n]\nDepth = 1","category":"page"},{"location":"index.html#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"","category":"page"},{"location":"tutorials/hyper_parameters.html#Hyper-Parameter-Learning","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"","category":"section"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"This methodology maintains the structure of the Bundle Method, particularly the resolution of the (Quadratic) Master Problem (MP).   It uses an ML model based on Recursion to compute, at each step, a regularization parameter used as a weight for the Euclidean distance with respect to the best point found so far in the MP.","category":"page"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"We assume that you have already downloaded or created your data and saved it in ./data/<your_folder>/.   This folder should contain 2000 instances, with 1000 for training, 500 for validation, and 500 for testing.","category":"page"},{"location":"tutorials/hyper_parameters.html#Training","page":"Hyper-Parameter Learning","title":"Training","text":"","category":"section"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"Here we show how to train a model.","category":"page"},{"location":"tutorials/hyper_parameters.html#Without-Batch","page":"Hyper-Parameter Learning","title":"Without Batch","text":"","category":"section"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"julia --project=. ./runs/runTrainingT.jl --data ./data/<your_folder>/ --lr 1.0e-4 --cn 5 --mti 4 --mvi 4 --seed 1 --maxIT 10 --maxEP 10 --cr_init false --telescopic true --instance_features true --gamma 0.9 --single_prediction false","category":"page"},{"location":"tutorials/hyper_parameters.html#With-Batch","page":"Hyper-Parameter Learning","title":"With Batch","text":"","category":"section"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"No mechanism to handle batch training is implemented for this model.","category":"page"},{"location":"tutorials/hyper_parameters.html#Parameters-Explanation","page":"Hyper-Parameter Learning","title":"Parameters Explanation","text":"","category":"section"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"--data ./data/<your_folder>/ : The data folder containing the dataset of instances.\n--lr 1.0e-4 : The learning rate for updating the model parameters.\n--cn 5 : Coefficient to prevent the gradient norm from becoming too large.\n--mti 1000 : Number of training instances.\n--mvi 500 : Number of validation instances.\n--seed 1 : Random seed.\n--maxIT 10 : Number of iterations (unrolls) of the Bundle method at each call.\n--maxEP 10 : Number of training epochs.\n--cr_init false : If false, start from the zero vector; otherwise, from the dual solution of the continuous relaxation (CR). Works only in the Lagrangian relaxation (LR) setting, assuming CR is easy to solve but provides a poor bound compared to LR.\n--telescopic true : If true, considers a telescopic sum of all visited points during execution.\n--instance_features true : If true, adds features depending on the instance (static during execution).\n--gamma 0.9 : Coefficient in the telescopic sum, larger for the last point, smaller for earlier points. Null Steps have lower contribution.\n--single_prediction false : If true, uses only one prediction; otherwise, multiple ones obtained with a recurrent model.","category":"page"},{"location":"tutorials/hyper_parameters.html#Testing","page":"Hyper-Parameter Learning","title":"Testing","text":"","category":"section"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"julia --project=. ./runs/runTestT.jl --data ./data/<your_folder>/ --model ./res/res_goldLossWeights_withInstFeat_initZero_lr0.0001_cn5_maxIT10_maxEP10_data<your_folder>_exactGradtrue_gamma0.9_seed1_single_predictionfalse_0.0_ --dataset ./res/BatchVersion_bs_1_true_<your_folder>_0.0001_0.9_5_4_4_1_10_10_true_32_false_softplus_false_0.999_0.0_0.0_sparsemax_false_false_1.0/","category":"page"},{"location":"tutorials/hyper_parameters.html#Parameters-Explanation-2","page":"Hyper-Parameter Learning","title":"Parameters Explanation","text":"","category":"section"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"--data ./data/<your_folder>/ : The folder containing the dataset.\n--dataset ./res/BatchVersion_bs_1_true_<your_folder>_0.0001_0.9_5_1000_500_1_10_100_true_32_false_softplus_false_0.999_0.0_0.0_sparsemax_false_false_1.0/ : The model folder, typically obtained from training.\n--model : (Optional) Path to a specific model. If not provided, defaults to the test instances associated with the training. To test a specific set, pass the path to a folder containing a dataset.json file, saved during training.","category":"page"},{"location":"tutorials/hyper_parameters.html#Further-References","page":"Hyper-Parameter Learning","title":"Further References","text":"","category":"section"},{"location":"tutorials/hyper_parameters.html","page":"Hyper-Parameter Learning","title":"Hyper-Parameter Learning","text":"Bundle Network: A fully ML-based Bundle Method.\nBaselines: Grid-search based baselines, including classic (aggregated) Bundle method with different T-strategies (tuning strategies for the regularization parameter), Adam, and Descent.","category":"page"}]
}
