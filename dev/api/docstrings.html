<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Docstrings · BundleNetworks Documentation</title><meta name="title" content="Docstrings · BundleNetworks Documentation"/><meta property="og:title" content="Docstrings · BundleNetworks Documentation"/><meta property="twitter:title" content="Docstrings · BundleNetworks Documentation"/><meta name="description" content="Documentation for BundleNetworks Documentation."/><meta property="og:description" content="Documentation for BundleNetworks Documentation."/><meta property="twitter:description" content="Documentation for BundleNetworks Documentation."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">BundleNetworks Documentation</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Home</a></li><li><a class="tocitem" href="../installation.html">Installation</a></li><li><a class="tocitem" href="../quickstart.html">Quick Start</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/batch_training.html">Batch Training</a></li><li><a class="tocitem" href="../tutorials/episodic_training.html">Episodic Training</a></li><li><a class="tocitem" href="../tutorials/testing.html">Inference &amp; Evaluation</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../manual/architecture.html">Architecture</a></li></ul></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="training.html">Training Functions</a></li></ul></li><li><a class="tocitem" href="../examples.html">Examples</a></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="training.html">Training Functions</a></li><li class="is-active"><a class="tocitem" href="docstrings.html">Docstrings</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Reference</a></li><li class="is-active"><a href="docstrings.html">Docstrings</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="docstrings.html">Docstrings</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FDemelas/bundlenetwork.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/FDemelas/bundlenetwork.jl/blob/main/docs/src/api/docstrings.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Docstrings"><a class="docs-heading-anchor" href="#API-Docstrings">API Docstrings</a><a id="API-Docstrings-1"></a><a class="docs-heading-anchor-permalink" href="#API-Docstrings" title="Permalink"></a></h1><div class="admonition is-warning" id="Missing-docstring.-e9db25332a861c34"><header class="admonition-header">Missing docstring.<a class="admonition-anchor" href="#Missing-docstring.-e9db25332a861c34" title="Permalink"></a></header><div class="admonition-body"><p>Missing docstring for <code>InnerLoss</code>. Check Documenter&#39;s build log for details.</p></div></div><article><details class="docstring" open="true"><summary id="BundleNetworks.constructFunction"><a class="docstring-binding" href="#BundleNetworks.constructFunction"><code>BundleNetworks.constructFunction</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">constructFunction(data, rescaling_factor::Real, layers = [28 * 28, 20, 10])</code></pre><p>Constructs an <code>InnerLoss</code> function for MNIST classification.</p><p><strong>Arguments</strong></p><ul><li><code>data</code>: Tuple <code>(x, y)</code> containing input images and labels<ul><li><code>x</code>: Images as 3D array (28, 28, batch<em>size) or 2D (784, batch</em>size)</li><li><code>y</code>: Integer labels (batch_size,) with values 0-9</li></ul></li><li><code>rescaling_factor::Real</code>: Divisor for loss scaling (default: no specific default shown)</li><li><code>layers</code>: Network architecture specification (default: [784, 20, 10])</li></ul><p><strong>Returns</strong></p><ul><li><code>InnerLoss</code> instance ready for training or inference</li></ul><p><strong>Default Architecture</strong></p><pre><code class="language-julia hljs">[28 × 28, 20, 10] = [784, 20, 10]
- Input layer: 784 neurons (28×28 pixels)
- Hidden layer: 20 neurons
- Output layer: 10 neurons (one per digit class)</code></pre><p><strong>Data Preprocessing</strong></p><p>Performs several transformations on input data:</p><p><strong>Label Encoding</strong></p><p>Converts integer labels to one-hot vectors:</p><pre><code class="language-julia hljs"># Input: y = [3, 7, 2, ...]  (class indices 0-9)
# Output: y = [[0,0,0,1,0,0,0,0,0,0],
#              [0,0,0,0,0,0,0,1,0,0],
#              [0,0,1,0,0,0,0,0,0,0], ...]
#         (10 × batch_size matrix)</code></pre><p><strong>Image Reshaping</strong></p><p>Flattens 2D images to vectors:</p><pre><code class="language-julia hljs"># Input: x shape (28, 28, batch_size)
# Output: x shape (784, batch_size)</code></pre><p><strong>Loss Function</strong></p><p>Uses <strong>negative logit cross-entropy</strong> for maximization:</p><pre><code class="language-julia hljs">f(ŷ, y) = -Flux.logitcrossentropy(ŷ, y)</code></pre><p>The negative sign converts minimization to maximization, which is the convention for <code>AbstractConcaveFunction</code>.</p><p><strong>Cross-Entropy Loss</strong></p><p>Logit cross-entropy directly on logits (before softmax):</p><pre><code class="language-julia hljs">CE(ŷ, y) = -Σᵢ yᵢ log(softmax(ŷ)ᵢ)</code></pre><p>More numerically stable than applying softmax then computing entropy.</p><p><strong>Device Handling</strong></p><p>Automatically moves data to appropriate device (CPU/GPU):</p><ul><li><code>device(x)</code>: Moves images to current device</li><li><code>device(y)</code>: Moves labels to current device</li><li><code>cpu(layers)</code>: Keeps architecture spec on CPU (metadata)</li></ul><p><strong>Rescaling Factor Guidelines</strong></p><p>The rescaling factor affects optimization dynamics:</p><ul><li><strong>Too small</strong> (e.g., 1.0): Large gradient magnitudes, potential instability</li><li><strong>Too large</strong> (e.g., 10000.0): Small gradients, slow learning</li><li><strong>Recommended</strong>: 10-1000 depending on batch size and architecture</li></ul><p>Typical values:</p><ul><li>Small networks: 10-50</li><li>Medium networks: 50-200</li><li>Large networks: 100-1000</li></ul><p><strong>See Also</strong></p><ul><li><code>sizeInputSpace</code>: Compute required parameter vector size</li><li><code>prediction</code>: Inference without loss computation</li><li><code>value_gradient</code>: Compute loss and gradients</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/InnerLoss.jl#L251-L332">source</a></section><section><div><pre><code class="language-julia hljs">constructFunction(inst::cpuInstanceMCND, rescaling_factor::Real=1.0)</code></pre><p>Constructs a Lagrangian function from an MCND problem instance.</p><p><strong>Arguments</strong></p><ul><li><code>inst::cpuInstanceMCND</code>: MCND problem instance from Instances package<ul><li>Must contain: K (commodities), N (nodes), E (arcs)</li><li>Network topology, costs, capacities, demands</li></ul></li><li><code>rescaling_factor::Real</code>: Scaling factor for objective (default: 1.0)</li></ul><p><strong>Returns</strong></p><ul><li><code>LagrangianFunctionMCND</code>: Callable Lagrangian function</li></ul><p><strong>Instance Requirements</strong></p><p>The <code>cpuInstanceMCND</code> instance must contain:</p><ul><li><code>K::Int</code>: Number of commodities</li><li><code>N::Int</code>: Number of nodes in network</li><li><code>E::Int</code>: Number of arcs (directed edges)</li><li>Network structure: head, tail functions for arcs</li><li><code>cost::Vector{Float32}</code>: Arc costs (E,)</li><li><code>capacity::Vector{Float32}</code>: Arc capacities (E,)</li><li>Demand information: b function for node demands</li></ul><p><strong>Rescaling Factor Guidelines</strong></p><p>Used to normalize Lagrangian values:</p><ul><li><strong>Small networks</strong> (K, N, E &lt; 100): 1.0 - 10.0</li><li><strong>Medium networks</strong> (K, N, E &lt; 1000): 10.0 - 100.0</li><li><strong>Large networks</strong> (K, N, E &gt; 1000): 100.0 - 1000.0</li></ul><p>Choose to keep L(z) values in range [0.1, 1000] for numerical stability.</p><p><strong>Network Topology Functions</strong></p><p>The instance provides helper functions:</p><ul><li><code>head(inst, arc)</code>: Head node of arc</li><li><code>tail(inst, arc)</code>: Tail node of arc</li><li><code>b(inst, node, commodity)</code>: Demand at node for commodity</li><li><code>sizeE(inst)</code>: Number of arcs</li><li><code>sizeLM(inst)</code>: Dual variable dimensions</li></ul><p><strong>See Also</strong></p><ul><li><code>Instances</code> package documentation</li><li><code>LagrangianFunctionMCND</code>: Resulting structure</li><li><code>sizeInputSpace</code>: Verify dual dimensions</li><li><code>numberSP</code>: Verify arc count</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/LagrangianMCND.jl#L206-L252">source</a></section><section><div><pre><code class="language-julia hljs">constructFunction(inst::cpuInstanceGA, rescaling_factor::Real=1.0)</code></pre><p>Constructs a Lagrangian function from a problem instance.</p><p><strong>Arguments</strong></p><ul><li><code>inst::cpuInstanceGA</code>: Problem instance from Instances package<ul><li>Contains: I (items), J (commodities), p, w, c arrays</li></ul></li><li><code>rescaling_factor::Real</code>: Scaling factor for objective (default: 1.0)</li></ul><p><strong>Returns</strong></p><ul><li><code>LagrangianFunctionGA</code>: Callable Lagrangian function</li></ul><p><strong>Instance Requirements</strong></p><p>The <code>cpuInstanceGA</code> instance must contain:</p><ul><li><code>I::Int</code>: Number of items (arcs in network)</li><li><code>J::Int</code>: Number of commodities</li><li><code>p::Matrix{Float32}</code>: Profit matrix (I × J)</li><li><code>w::Matrix{Float32}</code>: Weight matrix (I × J)</li><li><code>c::Vector{Float32}</code>: Capacity vector (J,)</li></ul><p><strong>Rescaling Factor</strong></p><p>Used to normalize objective values:</p><ul><li><strong>Too small</strong>: May cause numerical overflow</li><li><strong>Too large</strong>: May cause underflow or slow convergence</li><li><strong>Recommended</strong>: Scale to keep L(z) in range [0.1, 1000]</li></ul><p>Typical values:</p><ul><li>Small instances (I, J &lt; 100): 1.0 - 10.0</li><li>Medium instances (I, J &lt; 1000): 10.0 - 100.0</li><li>Large instances (I, J &gt; 1000): 100.0 - 1000.0</li></ul><p><strong>See Also</strong></p><ul><li><code>Instances</code> package: Problem instance management</li><li><code>LagrangianFunctionGA</code>: Resulting structure</li><li><code>sizeInputSpace</code>: Verify dimension</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/LagrangianGA.jl#L171-L207">source</a></section><section><div><pre><code class="language-julia hljs">constructFunction(inst::Instances.TUC, rescaling_factor::Real=1.0)</code></pre><p>Constructs a Lagrangian function from a unit commitment problem instance.</p><p><strong>Arguments</strong></p><ul><li><code>inst::Instances.TUC</code>: UC problem instance from Instances package<ul><li>Must contain: I (units), T (periods), D (demand), costs, constraints</li></ul></li><li><code>rescaling_factor::Real</code>: Scaling factor for objective (default: 1.0)</li></ul><p><strong>Returns</strong></p><ul><li><code>LagrangianFunctionUC</code>: Callable Lagrangian function</li></ul><p><strong>Instance Requirements</strong></p><p>The <code>Instances.TUC</code> instance must contain:</p><ul><li><code>I::Int</code>: Number of generating units</li><li><code>T::Int</code>: Number of time periods (horizon length)</li><li><code>D::Vector{Float32}</code>: Demand profile (T,)</li><li>Unit characteristics for each generator:<ul><li>Capacity limits (min/max generation)</li><li>Startup/shutdown costs</li><li>Generation cost curves</li><li>Minimum up/down times</li><li>Ramping rates</li></ul></li></ul><p><strong>Rescaling Factor Guidelines</strong></p><p>Used to normalize Lagrangian values for numerical stability:</p><p><strong>Small systems</strong> (I, T &lt; 10): 1.0 - 100.0 <strong>Medium systems</strong> (I, T &lt; 100): 100.0 - 1000.0 <strong>Large systems</strong> (I, T &gt; 100): 1000.0 - 10000.0</p><p>Choose to keep L(z) values in range [0.1, 10000] for stable gradients.</p><p><strong>See Also</strong></p><ul><li><code>Instances.TUC</code>: Instance structure documentation</li><li><code>LagrangianFunctionUC</code>: Resulting structure</li><li><code>sizeInputSpace</code>: Number of time periods (T)</li><li><code>numberSP</code>: Number of units (I)</li><li>Unit commitment problem formulation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/LagrangianTUC.jl#L219-L259">source</a></section></details></article><div class="admonition is-warning" id="Missing-docstring.-319eed0b14a3ee50"><header class="admonition-header">Missing docstring.<a class="admonition-anchor" href="#Missing-docstring.-319eed0b14a3ee50" title="Permalink"></a></header><div class="admonition-body"><p>Missing docstring for <code>prediction</code>. Check Documenter&#39;s build log for details.</p></div></div><article><details class="docstring" open="true"><summary id="BundleNetworks.sizeInputSpace"><a class="docstring-binding" href="#BundleNetworks.sizeInputSpace"><code>BundleNetworks.sizeInputSpace</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">sizeInputSpace(l::InnerLoss)</code></pre><p>Computes the dimension of the parameter space for the neural network.</p><p><strong>Arguments</strong></p><ul><li><code>l::InnerLoss</code>: The inner loss function structure</li></ul><p><strong>Returns</strong></p><ul><li><code>Int</code>: Total number of parameters in the network</li></ul><p><strong>Formula</strong></p><p>For a network with architecture [d₁, d₂, ..., dₙ]:</p><pre><code class="language-julia hljs">Total parameters = Σᵢ₌₁ⁿ⁻¹ (dᵢ × dᵢ₊₁ + dᵢ₊₁)
                 = Σᵢ₌₁ⁿ⁻¹ dᵢ₊₁(dᵢ + 1)</code></pre><p>Where:</p><ul><li><code>dᵢ × dᵢ₊₁</code>: Weight matrix parameters for layer i</li><li><code>dᵢ₊₁</code>: Bias vector parameters for layer i</li></ul><p><strong>Breakdown by Layer</strong></p><p>For each layer connection i → i+1:</p><ul><li><strong>Weights</strong>: <code>layers[i] × layers[i+1]</code> parameters</li><li><strong>Biases</strong>: <code>layers[i+1]</code> parameters</li><li><strong>Total</strong>: <code>layers[i] × layers[i+1] + layers[i+1]</code></li></ul><p><strong>Relationship to Network Capacity</strong></p><p>The parameter count determines:</p><ul><li><strong>Model capacity</strong>: More parameters → more expressiveness</li><li><strong>Memory requirements</strong>: Linear in parameter count</li><li><strong>Training time</strong>: More parameters → slower training</li><li><strong>Overfitting risk</strong>: More parameters → higher risk with small datasets</li></ul><p><strong>See Also</strong></p><ul><li><code>constructFunction</code>: Creates InnerLoss with specified architecture</li><li>Parameter initialization strategies</li><li>Network architecture design</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/InnerLoss.jl#L358-L397">source</a></section><section><div><pre><code class="language-julia hljs">sizeInputSpace(ϕ::LagrangianFunctionMCND)</code></pre><p>Returns the dimensions of the dual variable space.</p><p><strong>Arguments</strong></p><ul><li><code>ϕ::LagrangianFunctionMCND</code>: The Lagrangian function</li></ul><p><strong>Returns</strong></p><ul><li><code>(K, N)</code>: Tuple of dimensions<ul><li>K: Number of commodities</li><li>N: Number of nodes in network</li></ul></li></ul><p><strong>Explanation</strong></p><p>The Lagrangian has one dual variable per (commodity, node) pair:</p><ul><li>Each commodity k has N dual variables (one per node)</li><li>Total: K × N dual variables</li></ul><p>These correspond to the flow conservation constraints at each node for each commodity.</p><p><strong>Relationship to Instance</strong></p><pre><code class="language-julia hljs">sizeInputSpace(ϕ) == sizeLM(ϕ.inst) == (K, N)</code></pre><p><strong>See Also</strong></p><ul><li><code>sizeLM</code>: Underlying function from Instances package</li><li><code>numberSP</code>: Number of arcs (subproblems)</li><li>Network dimensions and complexity</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/LagrangianMCND.jl#L412-L443">source</a></section><section><div><pre><code class="language-julia hljs">sizeInputSpace(ϕ::LagrangianFunctionGA)</code></pre><p>Returns the dimension of the dual variable space.</p><p><strong>Arguments</strong></p><ul><li><code>ϕ::LagrangianFunctionGA</code>: The Lagrangian function</li></ul><p><strong>Returns</strong></p><ul><li><code>Int</code>: Dimension of dual variables (equals number of items I)</li></ul><p><strong>Explanation</strong></p><p>The Lagrangian has one dual variable per relaxed constraint. For the knapsack relaxation of MCND:</p><ul><li>Each item (arc) has one dual variable</li><li>Total: I dual variables</li></ul><p><strong>Relationship to Instance</strong></p><pre><code class="language-julia hljs">sizeInputSpace(ϕ) == ϕ.inst.I == sizeLM(ϕ.inst)</code></pre><p>Where:</p><ul><li><code>I</code>: Number of items in the problem</li><li><code>sizeLM</code>: Size of Lagrange multiplier vector</li></ul><p><strong>See Also</strong></p><ul><li><code>sizeLM</code>: Underlying function from Instances package</li><li><code>numberSP</code>: Returns number of subproblems (J)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/LagrangianGA.jl#L358-L387">source</a></section><section><div><pre><code class="language-julia hljs">sizeInputSpace(ϕ::LagrangianFunctionUC)</code></pre><p>Returns the dimension of the dual variable space (number of time periods).</p><p><strong>Arguments</strong></p><ul><li><code>ϕ::LagrangianFunctionUC</code>: The Lagrangian function</li></ul><p><strong>Returns</strong></p><ul><li><code>Int</code>: Number of time periods T in the planning horizon</li></ul><p><strong>Explanation</strong></p><p>The Lagrangian has one dual variable (price) per time period:</p><ul><li>Each time period t has one demand constraint</li><li>Each constraint has one Lagrange multiplier z[t]</li><li>Total: T dual variables</li></ul><p>These represent electricity prices at each time period.</p><p><strong>Relationship to Instance</strong></p><pre><code class="language-julia hljs">sizeInputSpace(ϕ) == Instances.nT(ϕ.inst) == T</code></pre><p><strong>See Also</strong></p><ul><li><code>Instances.nT</code>: Underlying function from Instances package</li><li><code>numberSP</code>: Number of generators (I)</li><li>UC problem horizon selection</li><li>Temporal resolution trade-offs</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/LagrangianTUC.jl#L413-L442">source</a></section></details></article><div class="admonition is-warning" id="Missing-docstring.-710a3d6368dde11a"><header class="admonition-header">Missing docstring.<a class="admonition-anchor" href="#Missing-docstring.-710a3d6368dde11a" title="Permalink"></a></header><div class="admonition-body"><p>Missing docstring for <code>numberSP</code>. Check Documenter&#39;s build log for details.</p></div></div><article><details class="docstring" open="true"><summary id="BundleNetworks.value_gradient"><a class="docstring-binding" href="#BundleNetworks.value_gradient"><code>BundleNetworks.value_gradient</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">value_gradient(ϕ::AbstractConcaveFunction, z::AbstractArray)</code></pre><p>Computes both the function value and subgradient for a concave function.</p><p><strong>Arguments</strong></p><ul><li><code>ϕ::AbstractConcaveFunction</code>: The concave function to evaluate</li><li><code>z::AbstractArray</code>: The point at which to evaluate the function</li></ul><p><strong>Returns</strong></p><ul><li><code>value</code>: The function value ϕ(z)</li><li><code>gradient</code>: A subgradient ∂ϕ(z) (or gradient if ϕ is differentiable)</li></ul><p><strong>Mathematical Background</strong></p><p>For a concave function ϕ, a vector g is a <strong>subgradient</strong> at point z if:</p><pre><code class="language-julia hljs">ϕ(y) ≤ ϕ(z) + g&#39;(y - z)  for all y</code></pre><p>For differentiable concave functions, the gradient is the unique subgradient.</p><p><strong>Implementation Details</strong></p><ol><li><strong>CPU Transfer</strong>: Input is moved to CPU for computation</li><li><strong>Automatic Differentiation</strong>: Uses Flux.withgradient for gradient computation</li><li><strong>Device Transfer</strong>: Results are moved back to appropriate device (CPU/GPU)</li></ol><p><strong>Why CPU Transfer?</strong></p><p>Some operations may be more stable or only supported on CPU. The function ensures compatibility by:</p><ul><li>Moving input to CPU before computation</li><li>Computing on CPU</li><li>Moving results back to the original device</li></ul><p><strong>Numerical Considerations</strong></p><ul><li>Gradients are computed using automatic differentiation</li><li>For non-differentiable points, returns one valid subgradient</li><li>Ensures type consistency (Float32) for GPU compatibility</li></ul><p><strong>See Also</strong></p><ul><li><code>ChainRulesCore.rrule</code>: Custom backward pass implementation</li><li><code>AbstractConcaveFunction</code>: Base type requiring this interface</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/AbstractConcave.jl#L68-L110">source</a></section><section><div><pre><code class="language-julia hljs">value_gradient(ϕ::InnerLoss, z::AbstractArray)</code></pre><p>Computes loss value and gradient for the inner loss function.</p><p><strong>Arguments</strong></p><ul><li><code>ϕ::InnerLoss</code>: The inner loss function</li><li><code>z::AbstractArray</code>: Network parameters (flattened vector)</li></ul><p><strong>Returns</strong></p><ul><li><code>value</code>: Loss value (scalar)</li><li><code>gradient</code>: Gradient w.r.t. parameters (same shape as z)</li></ul><p><strong>Specialization</strong></p><p>This is a <strong>specialized implementation</strong> of <code>value_gradient</code> for <code>InnerLoss</code>. Unlike the default implementation in <code>AbstractConcaveFunction</code>, this version:</p><ul><li>Keeps data on GPU/CPU (no unnecessary transfers)</li><li>Uses <code>device(z)</code> to ensure parameters are on correct device</li></ul><p><strong>Why Override?</strong></p><p>The default <code>value_gradient</code> for <code>AbstractConcaveFunction</code>:</p><ol><li>Moves input to CPU: <code>z = cpu(z)</code></li><li>Computes on CPU</li><li>Moves results back: <code>device(obj), device(grad[1])</code></li></ol><p>For neural networks, this is inefficient because:</p><ul><li>Networks benefit from GPU acceleration</li><li>CPU ↔ GPU transfers are expensive</li><li>Gradients are large (thousands of parameters)</li></ul><p><strong>Performance Considerations</strong></p><ul><li><strong>GPU acceleration</strong>: Keeps computation on GPU throughout</li><li><strong>Memory efficiency</strong>: No unnecessary copies</li><li><strong>Batch processing</strong>: Efficiently handles batched data</li></ul><p><strong>See Also</strong></p><ul><li><code>value_gradient(::AbstractConcaveFunction, ...)</code>: Default implementation</li><li><code>Flux.withgradient</code>: Automatic differentiation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FDemelas/bundlenetwork.jl/blob/4f52434fa81f01b9db2f0845b66deeaf402e0da4/src/ObjectiveFunctions/InnerLoss.jl#L429-L468">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="training.html">« Training Functions</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 19 February 2026 09:12">Thursday 19 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
